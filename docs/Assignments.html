<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Assignments for Crim 250</title>

<script src="site_libs/header-attrs-2.10/header-attrs.js"></script>
<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>








<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Johanna Learns R - Crim 250</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="Assignments.html">Assignments</a>
</li>
<li>
  <a href="Links.html">Links</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Assignments for Crim 250</h1>

</div>


<p>This page will contain all the assignments you submit for the class.</p>
<p>This page will contain all the assignments you submit for the class.</p>
<div id="instructions-for-all-assignments" class="section level3">
<h3>Instructions for all assignments</h3>
<p>I want you to submit your assignment as a PDF, so I can keep a record of what the code looked like that day. I also want you to include your answers on your personal GitHub website. This will be good practice for editing your website and it will help you produce something you can keep after the class is over.</p>
<ol style="list-style-type: decimal">
<li><p>Download the Assignment1.Rmd file from Canvas. You can use this as a template for writing your answers. It’s the same as what you can see on my website in the Assignments tab. Once we’re done with this I’ll edit the text on the website to include the solutions.</p></li>
<li><p>On RStudio, open a new R script in RStudio (File &gt; New File &gt; R Script). This is where you can test out your R code. You’ll write your R commands and draw plots here.</p></li>
<li><p>Once you have finalized your code, copy and paste your results into this template (Assignment 1.Rmd). For example, if you produced a plot as the solution to one of the problems, you can copy and paste the R code in R markdown by using the <code>``{r} ```</code> command. Answer the questions in full sentences and Save.</p></li>
<li><p>Produce a PDF file with your answers. To do this, knit to PDF (use Knit button at the top of RStudio), locate the PDF file in your docs folder (it’s in the same folder as the Rproj), and submit that on on Canvas in Assignment 1.</p></li>
<li><p>Build Website, go to GitHub desktop, commit and push. Now your solutions should be on your website as well.</p></li>
</ol>
</div>
<div id="assignment-1" class="section level1">
<h1>Assignment 1</h1>
<p><strong>Collaborators: none. </strong></p>
<p>This assignment is due on Canvas on Monday 9/20 before class, at 10:15 am. Include the name of anyone with whom you collaborated at the top of the assignment.</p>
<div id="problem-1" class="section level3">
<h3>Problem 1</h3>
<p>Install the datasets package on the console below using <code>install.packages("datasets")</code>. Now load the library.</p>
<pre class="r"><code># install.packages(&quot;datasets&quot;)
library(datasets)</code></pre>
<p>Load the USArrests dataset and rename it <code>dat</code>. Note that this dataset comes with R, in the package datasets, so there’s no need to load data from your computer. Why is it useful to rename the dataset?</p>
<pre class="r"><code>USArrests</code></pre>
<pre><code>##                Murder Assault UrbanPop Rape
## Alabama          13.2     236       58 21.2
## Alaska           10.0     263       48 44.5
## Arizona           8.1     294       80 31.0
## Arkansas          8.8     190       50 19.5
## California        9.0     276       91 40.6
## Colorado          7.9     204       78 38.7
## Connecticut       3.3     110       77 11.1
## Delaware          5.9     238       72 15.8
## Florida          15.4     335       80 31.9
## Georgia          17.4     211       60 25.8
## Hawaii            5.3      46       83 20.2
## Idaho             2.6     120       54 14.2
## Illinois         10.4     249       83 24.0
## Indiana           7.2     113       65 21.0
## Iowa              2.2      56       57 11.3
## Kansas            6.0     115       66 18.0
## Kentucky          9.7     109       52 16.3
## Louisiana        15.4     249       66 22.2
## Maine             2.1      83       51  7.8
## Maryland         11.3     300       67 27.8
## Massachusetts     4.4     149       85 16.3
## Michigan         12.1     255       74 35.1
## Minnesota         2.7      72       66 14.9
## Mississippi      16.1     259       44 17.1
## Missouri          9.0     178       70 28.2
## Montana           6.0     109       53 16.4
## Nebraska          4.3     102       62 16.5
## Nevada           12.2     252       81 46.0
## New Hampshire     2.1      57       56  9.5
## New Jersey        7.4     159       89 18.8
## New Mexico       11.4     285       70 32.1
## New York         11.1     254       86 26.1
## North Carolina   13.0     337       45 16.1
## North Dakota      0.8      45       44  7.3
## Ohio              7.3     120       75 21.4
## Oklahoma          6.6     151       68 20.0
## Oregon            4.9     159       67 29.3
## Pennsylvania      6.3     106       72 14.9
## Rhode Island      3.4     174       87  8.3
## South Carolina   14.4     279       48 22.5
## South Dakota      3.8      86       45 12.8
## Tennessee        13.2     188       59 26.9
## Texas            12.7     201       80 25.5
## Utah              3.2     120       80 22.9
## Vermont           2.2      48       32 11.2
## Virginia          8.5     156       63 20.7
## Washington        4.0     145       73 26.2
## West Virginia     5.7      81       39  9.3
## Wisconsin         2.6      53       66 10.8
## Wyoming           6.8     161       60 15.6</code></pre>
<pre class="r"><code>dat &lt;- USArrests</code></pre>
<p>Answer: It is useful to rename the data set because it makes it easier to remember the name we give it to use in code commands later on in the assignment. It helps to separate the base R package dataset and turn it into our own dataset to use with the following work.</p>
</div>
<div id="problem-2" class="section level3">
<h3>Problem 2</h3>
<p>Use this command to make the state names into a new variable called State.</p>
<pre class="r"><code>dat$state &lt;- tolower(rownames(USArrests))</code></pre>
<p>This dataset has the state names as row names, so we just want to make them into a new variable. We also make them all lower case, because that will help us draw a map later - the map function requires the states to be lower case.</p>
<p>List the variables contained in the dataset <code>USArrests</code>.</p>
<pre class="r"><code>list(dat)</code></pre>
<pre><code>## [[1]]
##                Murder Assault UrbanPop Rape          state
## Alabama          13.2     236       58 21.2        alabama
## Alaska           10.0     263       48 44.5         alaska
## Arizona           8.1     294       80 31.0        arizona
## Arkansas          8.8     190       50 19.5       arkansas
## California        9.0     276       91 40.6     california
## Colorado          7.9     204       78 38.7       colorado
## Connecticut       3.3     110       77 11.1    connecticut
## Delaware          5.9     238       72 15.8       delaware
## Florida          15.4     335       80 31.9        florida
## Georgia          17.4     211       60 25.8        georgia
## Hawaii            5.3      46       83 20.2         hawaii
## Idaho             2.6     120       54 14.2          idaho
## Illinois         10.4     249       83 24.0       illinois
## Indiana           7.2     113       65 21.0        indiana
## Iowa              2.2      56       57 11.3           iowa
## Kansas            6.0     115       66 18.0         kansas
## Kentucky          9.7     109       52 16.3       kentucky
## Louisiana        15.4     249       66 22.2      louisiana
## Maine             2.1      83       51  7.8          maine
## Maryland         11.3     300       67 27.8       maryland
## Massachusetts     4.4     149       85 16.3  massachusetts
## Michigan         12.1     255       74 35.1       michigan
## Minnesota         2.7      72       66 14.9      minnesota
## Mississippi      16.1     259       44 17.1    mississippi
## Missouri          9.0     178       70 28.2       missouri
## Montana           6.0     109       53 16.4        montana
## Nebraska          4.3     102       62 16.5       nebraska
## Nevada           12.2     252       81 46.0         nevada
## New Hampshire     2.1      57       56  9.5  new hampshire
## New Jersey        7.4     159       89 18.8     new jersey
## New Mexico       11.4     285       70 32.1     new mexico
## New York         11.1     254       86 26.1       new york
## North Carolina   13.0     337       45 16.1 north carolina
## North Dakota      0.8      45       44  7.3   north dakota
## Ohio              7.3     120       75 21.4           ohio
## Oklahoma          6.6     151       68 20.0       oklahoma
## Oregon            4.9     159       67 29.3         oregon
## Pennsylvania      6.3     106       72 14.9   pennsylvania
## Rhode Island      3.4     174       87  8.3   rhode island
## South Carolina   14.4     279       48 22.5 south carolina
## South Dakota      3.8      86       45 12.8   south dakota
## Tennessee        13.2     188       59 26.9      tennessee
## Texas            12.7     201       80 25.5          texas
## Utah              3.2     120       80 22.9           utah
## Vermont           2.2      48       32 11.2        vermont
## Virginia          8.5     156       63 20.7       virginia
## Washington        4.0     145       73 26.2     washington
## West Virginia     5.7      81       39  9.3  west virginia
## Wisconsin         2.6      53       66 10.8      wisconsin
## Wyoming           6.8     161       60 15.6        wyoming</code></pre>
<pre class="r"><code>head(dat)</code></pre>
<pre><code>##            Murder Assault UrbanPop Rape      state
## Alabama      13.2     236       58 21.2    alabama
## Alaska       10.0     263       48 44.5     alaska
## Arizona       8.1     294       80 31.0    arizona
## Arkansas      8.8     190       50 19.5   arkansas
## California    9.0     276       91 40.6 california
## Colorado      7.9     204       78 38.7   colorado</code></pre>
<pre class="r"><code>names(dat)</code></pre>
<pre><code>## [1] &quot;Murder&quot;   &quot;Assault&quot;  &quot;UrbanPop&quot; &quot;Rape&quot;     &quot;state&quot;</code></pre>
<pre class="r"><code>summary(dat)</code></pre>
<pre><code>##      Murder          Assault         UrbanPop          Rape      
##  Min.   : 0.800   Min.   : 45.0   Min.   :32.00   Min.   : 7.30  
##  1st Qu.: 4.075   1st Qu.:109.0   1st Qu.:54.50   1st Qu.:15.07  
##  Median : 7.250   Median :159.0   Median :66.00   Median :20.10  
##  Mean   : 7.788   Mean   :170.8   Mean   :65.54   Mean   :21.23  
##  3rd Qu.:11.250   3rd Qu.:249.0   3rd Qu.:77.75   3rd Qu.:26.18  
##  Max.   :17.400   Max.   :337.0   Max.   :91.00   Max.   :46.00  
##     state          
##  Length:50         
##  Class :character  
##  Mode  :character  
##                    
##                    
## </code></pre>
</div>
<div id="problem-3" class="section level3">
<h3>Problem 3</h3>
<p>What type of variable (from the DVB chapter) is <code>Murder</code>?</p>
<p>Answer: Murder is a quantitative variable, because there are measured numerical values representing murder rates for each state.</p>
<p>What R Type of variable is it?</p>
<p>Answer: Murder is a character variable, as seen in the summary (dat) description in the code above.</p>
</div>
<div id="problem-4" class="section level3">
<h3>Problem 4</h3>
<p>What information is contained in this dataset, in general? What do the numbers mean?</p>
<p>Answer: This dataset contains the number of Murders, Assaults, and Rapes in each of the 50 states in the year 1973. It also shows us how many people lived in an urban area each state in that year, demonstrated by “UrbanPop.”</p>
</div>
<div id="problem-5" class="section level3">
<h3>Problem 5</h3>
<p>Draw a histogram of <code>Murder</code> with proper labels and title.</p>
<pre class="r"><code># histogram of Murder
hist(dat$Murder, main=&quot;Histogram of Murder&quot;, xlab=&quot;Murder Rate&quot;, ylab=&quot;Frequency&quot;)</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-5-1.png" width="480" /></p>
</div>
<div id="problem-6" class="section level3">
<h3>Problem 6</h3>
<p>Please summarize <code>Murder</code> quantitatively. What are its mean and median? What is the difference between mean and median? What is a quartile, and why do you think R gives you the 1st Qu. and 3rd Qu.?</p>
<pre class="r"><code>#Summary of Murder
summary(dat$Murder)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   0.800   4.075   7.250   7.788  11.250  17.400</code></pre>
<p>Answer: The mean of Murder is 7.788, the median of Murder is 7.250. Mean represents the average number of murders between the 50 states in 1973, whereas mean is the middle number of murders if the quantities were lined up in numerical order. Quartiles are 4 approximately evenly sized groups with the data ordered from least to greatest. R most likely gives us Q1 and Q3 because the values between these two represent the middle 50% of the data, and provide more context for the spread of the mean.</p>
</div>
<div id="problem-7" class="section level3">
<h3>Problem 7</h3>
<p>Repeat the same steps you followed for <code>Murder</code>, for the variables <code>Assault</code> and <code>Rape</code>. Now plot all three histograms together. You can do this by using the command <code>par(mfrow=c(3,1))</code> and then plotting each of the three.</p>
<pre class="r"><code>#histogram of Assault
hist(dat$Assault, main=&quot;Histogram of Assault&quot;, xlab=&quot;Assault Rate&quot;, ylab=&quot;Frequency&quot;)</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-7-1.png" width="480" /></p>
<pre class="r"><code>#Summary of Assault
summary(dat$Assault)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    45.0   109.0   159.0   170.8   249.0   337.0</code></pre>
<pre class="r"><code>#Histogram of Rape
hist(dat$Rape, main=&quot;Histogram of Rape&quot;, xlab=&quot;Rape Rate&quot;, ylab=&quot;Frequency&quot;)</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-7-2.png" width="480" /></p>
<pre class="r"><code>#Summary of Rape
summary(dat$Rape)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    7.30   15.07   20.10   21.23   26.18   46.00</code></pre>
<pre class="r"><code>#Histogram of Murder, Assault, Rape
par(mfrow=c(3,1))
hist(dat$Murder, main=&quot;Histogram of Murder&quot;, xlab=&quot;Murder Rate&quot;, ylab=&quot;Frequency&quot;)
hist(dat$Assault, main=&quot;Histogram of Assault&quot;, xlab=&quot;Assault Rate&quot;, ylab=&quot;Frequency&quot;)
hist(dat$Rape, main=&quot;Histogram of Rape&quot;, xlab=&quot;Rape Rate&quot;, ylab=&quot;Frequency&quot;)</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-7-3.png" width="480" /></p>
<p>What does the command par do, in your own words (you can look this up by asking R <code>?par</code>)?</p>
<p>Answer: the command par is used to set certain parameters within the data given to it. In this case, we used the par function to tell R that we wanted to plot 3 character vectors on histograms together in one plot.</p>
<p>What can you learn from plotting the histograms together?</p>
<p>Answer: Plotting the 3 histograms together allows us to easily visually compare the frequency of murders, assaults, and rapes to see which crime was most common among the 50 states in the year 1973.</p>
</div>
<div id="problem-8" class="section level3">
<h3>Problem 8</h3>
<p>In the console below (not in text), type <code>install.packages("maps")</code> and press Enter, and then type <code>install.packages("ggplot2")</code> and press Enter. This will install the packages so you can load the libraries.</p>
<p>Run this code:</p>
<pre class="r"><code>library(&#39;maps&#39;) 
library(&#39;ggplot2&#39;) 

ggplot(dat, aes(map_id=state, fill=Murder)) + 
  geom_map(map=map_data(&quot;state&quot;)) + 
  expand_limits(x=map_data(&quot;state&quot;)$long, y=map_data(&quot;state&quot;)$lat)</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-8-1.png" width="720" /></p>
<p>What does this code do? Explain what each line is doing.</p>
<p>Answer: These lines of code are generating a dataframe that shows the map of the US, breaking up the information from the variable Murder into sections based on state. The lines also color-code the map based on the number of murders that occurred in that state.</p>
<p><span class="math display">\[\\[2in]\]</span></p>
</div>
</div>
<div id="assignment-2" class="section level1">
<h1>Assignment 2</h1>
<div id="subtitle-crim-250-statistics-for-the-social-sciences" class="section level2">
<h2>Subtitle: Crim 250: Statistics for the Social Sciences</h2>
<p>Name: Johanna Doherty Date: 09/24/2021</p>
</div>
<div id="problem-1-load-data" class="section level2">
<h2>Problem 1: Load data</h2>
<p>Set your working directory to the folder where you downloaded the data. setwd(“/Users/johannadoherty/Documents/FALL 21/CRIM 250/Assign 2”)</p>
<p>Read the data dat &lt;- read.csv(file = ‘dat.nsduh.small.1.csv’)</p>
<p>What are the dimensions of the dataset? names(dat) dim(dat)</p>
<p>Answer: The dimensions of the data are 7 variables/columns by 171 rows as seen above in the dimensions.</p>
</div>
<div id="problem-2-variables" class="section level2">
<h2>Problem 2: Variables</h2>
<p>Describe the variables in the dataset. Answer: These are all numeric variables in R, although not all are quantitative variables in the data set. For example, irsex is a qualitative variable, with two options male or female, but each sex has been coded to a corresponding number, either 1 or 2, to make it useful as a numeric variable in R.</p>
<p>What is this dataset about? Who collected the data, what kind of sample is it, and what was the purpose of generating the data? Answer: The dataset is about drug use and health in the United States. The NSDUH (National Survey of Drug Use and Health) collected the data from participants ages 12 years and older in 2019. This is an example of a state based sample survey. The purpose of collecting the data from this sample is to hopefully be able to generalize about the drug use habits and health of the wider US population.</p>
</div>
<div id="problem-3-age-and-gender" class="section level2">
<h2>Problem 3: Age and gender</h2>
<p>What is the age distribution of the sample like? Make sure you read the codebook to know what the variable values mean. hist(dat$age2) Answer: I used a histogram of the age2 variable (shown below) to demonstrate the distribution of age. Using the codebook to look at the meaning of the age2 variable, I can tell that the majority of respondents were between 35 and 49 years old (represented by the number 15 on this histogram). There was not a normal distribution of ages in this dataset, in fact the ages are skewed to the right, meaning there are more older participants than younger.</p>
<p>Do you think this age distribution representative of the US population? Why or why not? I do not think this is entirely representative of the distribution of ages in the US Population. While I do believe there are a lot of Americans falling into the 35-49 age group, I do not think there is such a drastically higher frequency of people of this age group than others. It is likely that this age group was just the most likely to fill out this kind of survey.</p>
<p>Is the sample balanced in terms of gender? If not, are there more females or males? hist(dat<span class="math inline">\(irsex) summary(dat\)</span>irsex)</p>
<p>Answer: (in this above histogram, 1 represents male and 2 represents female). The dataset is almost balanced in terms of gender, as can be seen in the histogram. However, there are slightly more males in the data set than females. This can also be seen when looking at summary data of the gender variable (screenshot above), the mean is 1.468, meaning there are slightly more males than females in this data set. If it were perfectly balanced the mean should be exactly 1.5.</p>
<p>Use this code to draw a stacked bar plot to view the relationship between sex and age. What can you conclude from this plot? tab.agesex &lt;- table(dat<span class="math inline">\(irsex, dat\)</span>age2) barplot(tab.agesex, main = “Stacked barchart”, xlab = “Age category”, ylab = “Frequency”, legend.text = rownames(tab.agesex), beside = FALSE) # Stacked bars (default)</p>
<p>Answer: From this plot we can conclude that while most age group are roughly evenly split between males and females, some categories are overwhelmingly one or the other. For example, age group 8 (19 years old) seems to be entirely female, while age groups 6 and 7 (17 and 18 years old) seem to be entirely male. Overall, there are roughly even amounts of males and females for each age group, but there are some outliers.</p>
</div>
<div id="problem-4-substance-use" class="section level2">
<h2>Problem 4: Substance use</h2>
<p>For which of the three substances included in the dataset (marijuana, alcohol, and cigarettes) do individuals tend to use the substance earlier? hist(dat<span class="math inline">\(mjage) hist(dat\)</span>cigage) hist(dat$iralcage)</p>
<p>Answer: From these histograms, it appears that a higher frequency of respondents first tried marijuana between the ages of 10-15 than any other substance. For both alcohol and cigarettes, the tallest/highest frequency age blocks were older/further to the right than for marijuana.</p>
</div>
<div id="problem-5-sexual-attraction" class="section level2">
<h2>Problem 5: Sexual attraction</h2>
<p>What does the distribution of sexual attraction look like? Is this what you expected? table(dat$sexatract)</p>
<p>(For this variable; 1=heterosexual, 2=mostly attracted to opposite sex, 3=equally attracted to males and females, 4=mostly attracted to same sex, 5=only attracted to same sex, 6=not sure, 97=refused, 98=blank, 99=legitimate skip.)</p>
<p>Answer: It looks like the vast majority of respondents are heterosexual (only attracted to the opposite gender), which is pretty much expected given the demographics of the US population.</p>
<p>What is the distribution of sexual attraction by gender? tab.gendersexatract &lt;- table(dat<span class="math inline">\(sexatract, dat\)</span>irsex) barplot(tab.gendersexatract, main = “Stacked barchart”, xlab = “Gender Category”, ylab = “Frequency”, legend.text = rownames(tab.gendersexatract), beside = FALSE) # Stacked bars (default)</p>
<p>Answer: The distribution of sexual attraction by gender show that the sexual orientations of the females in this data set were more varied than those of the males. While the majority of both sexes still identified as straight, there were a higher frequency of women who identified as something other than straight as compared to the males.</p>
</div>
<div id="problem-6-english-speaking" class="section level2">
<h2>Problem 6: English speaking</h2>
<p>What does the distribution of English speaking look like in the sample? Is this what you might expect for a random sample of the US population? table(dat$speakengl)</p>
<p>Answer: The vast majority of respondents answered that they speak English very well, with only 21 selecting Well, and very few selecting anything less proficient than that. This does make sense to me, given that the national language of the US is English, but there are also a significant number of immigrants in the US that may not be as proficient in English. I would say that this is close to what I expected, but I may have expected to see more less proficient answers.</p>
<p>Are there more English speaker females or males? tab.sexspeakengl &lt;- table(dat<span class="math inline">\(speakengl, dat\)</span>irsex) barplot(tab.sexspeakengl, main = “Stacked barchart”, xlab = “Sex”, ylab = “Frequency”, legend.text = rownames(tab.sexspeakengl), beside = FALSE) # Stacked bars (default)</p>
<p>Answer: There are more English speaking males than females, but this is mainly because there are more males in the data set overall. There looks to be higher percentage of women that speak English “very well” compared to the men, but because there are a higher number of men overall, there are a higher number of men that speak English very well overall as well.</p>
</div>
</div>
<div id="exam-1" class="section level1">
<h1>“Exam 1”</h1>
<div id="author-johanna-doherty" class="section level2">
<h2>author: “Johanna Doherty”</h2>
<p>date: “10/04/2021” output: html_document</p>
<p>Instructions</p>
<ol style="list-style-type: lower-alpha">
<li><p>Create a folder in your computer (a good place would be under Crim 250, Exams).</p></li>
<li><p>Download the dataset from the Canvas website (fatal-police-shootings-data.csv) onto that folder, and save your Exam 1.Rmd file in the same folder.</p></li>
<li><p>Download the README.md file. This is the codebook.</p></li>
<li><p>Load the data into an R data frame.</p></li>
</ol>
<pre class="r"><code>setwd(&quot;/Users/johannadoherty/Documents/FALL 21/CRIM 250/EXAM 1&quot;)
dat&lt;-read.csv(&quot;fatal-police-shootings-data.csv&quot;)</code></pre>
<p>Problem 1 (10 points)</p>
<ol style="list-style-type: lower-alpha">
<li>Describe the dataset. This is the source: <a href="https://github.com/washingtonpost/data-police-shootings" class="uri">https://github.com/washingtonpost/data-police-shootings</a> . Write two sentences (max.) about this.</li>
</ol>
<p><strong>This data set, run by the Washington Post, contains every fatal shooting by U.S. police officers in the line of duty since January 2015.The data includes name of the victim, the date of the shooting, the manner of death, race, city, state and other relevant information about each shooting.</strong></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>How many observations are there in the data frame?</li>
</ol>
<pre class="r"><code>dim(dat)</code></pre>
<pre><code>## [1] 6594   17</code></pre>
<p><strong>There are 6594 observations for each of 17 variables in this data set..</strong></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Look at the names of the variables in the data frame. Describe what “body_camera”, “flee”, and “armed” represent, according to the codebook. Again, only write one sentence (max) per variable.</li>
</ol>
<pre class="r"><code>names(dat)</code></pre>
<pre><code>##  [1] &quot;id&quot;                      &quot;name&quot;                   
##  [3] &quot;date&quot;                    &quot;manner_of_death&quot;        
##  [5] &quot;armed&quot;                   &quot;age&quot;                    
##  [7] &quot;gender&quot;                  &quot;race&quot;                   
##  [9] &quot;city&quot;                    &quot;state&quot;                  
## [11] &quot;signs_of_mental_illness&quot; &quot;threat_level&quot;           
## [13] &quot;flee&quot;                    &quot;body_camera&quot;            
## [15] &quot;longitude&quot;               &quot;latitude&quot;               
## [17] &quot;is_geocoding_exact&quot;</code></pre>
<p><strong>Body_Camera indicates whether or not the officer was wearing a body camera at the time of the shooting. Flee represents whether the victim was moving away from officers and whether they were moving by foot or by car or other. Armed represents whether the victim was armed at the time of the shooting, and if so describes what they were armed with. </strong></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>What are three weapons that you are surprised to find in the “armed” variable? Make a table of the values in “armed” to see the options.</li>
</ol>
<pre class="r"><code>table(dat$armed)</code></pre>
<pre><code>## 
##                                                   air conditioner 
##                              207                                1 
##                       air pistol                   Airsoft pistol 
##                                1                                3 
##                               ax                         barstool 
##                               24                                1 
##                     baseball bat          baseball bat and bottle 
##                               20                                1 
## baseball bat and fireplace poker           baseball bat and knife 
##                                1                                1 
##                            baton                           BB gun 
##                                6                               15 
##               BB gun and vehicle                     bean-bag gun 
##                                1                                1 
##                      beer bottle                       binoculars 
##                                3                                1 
##                     blunt object                           bottle 
##                                5                                1 
##                    bow and arrow                       box cutter 
##                                1                               13 
##                            brick              car, knife and mace 
##                                2                                1 
##                          carjack                            chain 
##                                1                                3 
##                        chain saw                         chainsaw 
##                                2                                1 
##                            chair              claimed to be armed 
##                                4                                1 
##               contractor&#39;s level                   cordless drill 
##                                1                                1 
##                         crossbow                          crowbar 
##                                9                                5 
##                        fireworks                         flagpole 
##                                1                                1 
##                       flashlight                      garden tool 
##                                2                                2 
##                      glass shard                          grenade 
##                                4                                1 
##                              gun                      gun and car 
##                             3798                               12 
##                    gun and knife                  gun and machete 
##                               22                                3 
##                    gun and sword                  gun and vehicle 
##                                1                               17 
##              guns and explosives                           hammer 
##                                3                               18 
##                       hand torch                          hatchet 
##                                1                               14 
##                  hatchet and gun                         ice pick 
##                                2                                1 
##                incendiary device                            knife 
##                                2                              955 
##                knife and vehicle                 lawn mower blade 
##                                1                                2 
##                          machete                  machete and gun 
##                               51                                1 
##                     meat cleaver                  metal hand tool 
##                                6                                2 
##                     metal object                       metal pipe 
##                                5                               16 
##                       metal pole                       metal rake 
##                                4                                1 
##                      metal stick                       microphone 
##                                3                                1 
##                       motorcycle                         nail gun 
##                                1                                1 
##                              oar                       pellet gun 
##                                1                                3 
##                              pen                     pepper spray 
##                                1                                2 
##                         pick-axe                    piece of wood 
##                                4                                7 
##                             pipe                        pitchfork 
##                                7                                2 
##                             pole                   pole and knife 
##                                3                                2 
##                  railroad spikes                             rock 
##                                1                                7 
##                    samurai sword                         scissors 
##                                4                                9 
##                      screwdriver                     sharp object 
##                               16                               14 
##                           shovel                            spear 
##                                7                                2 
##                          stapler              straight edge razor 
##                                1                                5 
##                            sword                            Taser 
##                               23                               34 
##                        tire iron                       toy weapon 
##                                4                              226 
##                          unarmed                     undetermined 
##                              421                              188 
##                   unknown weapon                          vehicle 
##                               82                              213 
##                  vehicle and gun              vehicle and machete 
##                                8                                1 
##                    walking stick                       wasp spray 
##                                1                                1 
##                           wrench 
##                                1</code></pre>
<p><strong>I was definitely surprised to see an air conditioner, a nail gun, and wasp spray used as weapons against the police. </strong></p>
<p>Problem 2 (10 points)</p>
<ol style="list-style-type: lower-alpha">
<li>Describe the age distribution of the sample. Is this what you would expect to see?</li>
</ol>
<pre class="r"><code>hist(dat$age)</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p><strong>The distribution of age is skewed to the right, with the center focused around 30 years of age. This is pretty much what I would expect the age distribution to be, the most common age for crime to be committed is usually around 30 or under, so this may be a group that the police is most wary or suspicious of.</strong></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>To understand the center of the age distribution, would you use a mean or a median, and why? Find the one you picked.</li>
</ol>
<pre class="r"><code>summary(dat$age)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##    6.00   27.00   35.00   37.12   45.00   91.00     308</code></pre>
<p><strong>Since the data are slightly skewed, I will use the median to understand the center of the distribution, because this will reduce the impact of outliers on the center. The median of these data is 35 years of age.</strong></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Describe the gender distribution of the sample. Do you find this surprising?</li>
</ol>
<pre class="r"><code>table(dat$gender)</code></pre>
<pre><code>## 
##         F    M 
##    3  293 6298</code></pre>
<p><strong>There are way more male victims of fatal police shootings than females, as seen in the table above. This is not at all surprising to me, in America the stereotypical “criminal” is usually thought of as a young man, so it makes sense that the police might feel most threatened by people that fall into this category.</strong></p>
<p>Problem 3 (10 points)</p>
<ol style="list-style-type: lower-alpha">
<li>How many police officers had a body camera, according to news reports? What proportion is this of all the incidents in the data? Are you surprised that it is so high or low?</li>
</ol>
<pre class="r"><code>table(dat$body_camera)</code></pre>
<pre><code>## 
## False  True 
##  5684   910</code></pre>
<p><strong>910 of the recorded police officers were wearing a body camera, which is approximately 14% of the total recorded incidents. I am not surprised by how low this percentage is, I think that police officers have been generally resistant to the use of body cameras while in the field, and there are still many jurisdictions which do not enforce their use.</strong></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>In how many of the incidents was the victim fleeing? What proportion is this of the total number of incidents in the data? Is this what you would expect?</li>
</ol>
<pre class="r"><code>table(dat$flee)</code></pre>
<pre><code>## 
##                     Car        Foot Not fleeing       Other 
##         491        1058         845        3952         248</code></pre>
<pre class="r"><code>counts &lt;- table(dat$flee)
barplot(counts)</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p><strong>It is important to note that there is one unlabeled category in the fleeing variable, that represents 491 incidents. Given that we can not tell what this represents, we will omit it from the number and percentage of those who fled/did not flee. 2151 of the victims were fleeing at the time of the shooting. This represents roughly 35% of the total incidents. I would actually expect more than this percentage of victims to have been fleeing the scene, I’m surprised that a majority of the victims recorded were not fleeing than those who were.</strong></p>
<p>Problem 4 (10 points) - Answer only one of these (a or b).</p>
<ol style="list-style-type: lower-alpha">
<li>Describe the relationship between the variables “body camera” and “flee” using a stacked barplot. What can you conclude from this relationship?</li>
</ol>
<p><em>Hint 1: The categories along the x-axis are the options for “flee”, each bar contains information about whether the police officer had a body camera (vertically), and the height along the y-axis shows the frequency of that category).</em></p>
<p><em>Hint 2: Also, if you are unsure about the syntax for barplot, run ?barplot in R and see some examples at the bottom of the documentation. This is usually a good way to look up the syntax of R code. You can also Google it.</em></p>
<pre class="r"><code>tab.bodycamflee&lt;-table(dat$body_camera, dat$flee)
barplot(tab.bodycamflee, main = &quot;Stacked Barchart&quot;, xlab = &quot;Fleeing&quot;, ylab = &quot;Body Camera&quot;, legend.text = rownames(tab.bodycamflee),beside = FALSE) # Stacked bars (default)</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p><strong>It is important to note again that there is one unlabeled category in the fleeing variable, that represents 491 incidents. Given that we can not tell what this represents, we will omit it from the analysis of the barchart. In the above stacked barchat, we can see that there seems to be a similar proportion of officers wearing body cameras for each category of fleeing/not fleeing. Although we can see that the Not fleeing category has a higher number of officers wearing body cameras, there are also a higher number of not fleeing incidents as compared to the other categories, so proportionally they look pretty similar across the board. From this distribution, it seems that there is no obvious relationship between body camera wearing and victim fleeing patterns, as there are very similar proportions of body cameras for each category of fleeing. It’s possible that a stacked barchart was not the best option to represent the relationship between these data, as we can not surmise much about the relationship from looking at this graph. </strong></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Describe the relationship between age and race by using a boxplot. What can you conclude from this relationship?</li>
</ol>
<p><em>Hint 1: The categories along the x-axis are the race categories and the height along the y-axis is age.</em></p>
<p><em>Hint 2: Also, if you are unsure about the syntax for boxplot, run ?boxplot in R and see some examples at the bottom of the documentation. This is usually a good way to look up the syntax of R code. You can also Google it.</em></p>
<p><strong>Your answer here.</strong></p>
<p>Extra credit (10 points)</p>
<ol style="list-style-type: lower-alpha">
<li>What does this code tell us?</li>
</ol>
<pre class="r"><code>mydates &lt;- as.Date(dat$date)
head(mydates)
(mydates[length(mydates)] - mydates[1])</code></pre>
<p><strong>This code shows us the dates when each of the recorded shootings took place, and by looking at the first few rows of data, we can see that there were 6 shootings in the first 4 days of 2015. The last line of code tells us the number of days between the first recorded shooting in the dataset and the most recent, which is 2458 days or 6.7 years. Given that the first dates are in January 2015 and we are now in October of 2021, this time difference makes sense.</strong></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>On Friday, a new report was published that was described as follows by The Guardian: “More than half of US police killings are mislabelled or not reported, study finds.” Without reading this article now (due to limited time), why do you think police killings might be mislabelled or underreported?</li>
</ol>
<p><strong>I think that police shootings could be mis-labelled or under-reported due to them being classified as less severe than they are. For example, if a victim is shot by the police, but does not die until they are in the hospital hours later, this might be classified as just a shooting and not necessarily a fatal shooting since the victim did not die on the scene. Although there should be no gray area, and any person who dies after being shot by the police should be recorded as a fatal police shooting, I can see the potential for mislabelling and underreporting with situations that occurr under murkier circumstances. .</strong></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Regarding missing values in problem 4, do you see any? If so, do you think that’s all that’s missing from the data?</li>
</ol>
<p><strong>In the flee variable, there is an unlabeled category. Since we can not determine what these 491 incidents represent in terms of fleeing, we have to omit them from our analysis of the fleeing variable, which means we treat them as missing values. Given that this missing category exists, it would not surprise me to see that other variables have missing data as well. Given that “fleeing” could be seen as a matter of opinion or a subjective question in some challenging circumstances, it makes sense to me that there might be missing data in this variable. It seems possible that some of the other variables with “gray areas” or that are less clear cut could have missing data as well.</strong></p>
</div>
</div>
<div id="assignment-3" class="section level1">
<h1>“Assignment 3”</h1>
<div id="johanna-doherty" class="section level2">
<h2>“Johanna Doherty”</h2>
<p>date: “Today’s date here: 10/26/2021” output: html_document</p>
<p><strong>Collaborators: </strong>.</p>
<p>This assignment is due on Canvas on Wednesday 10/27/2021 before class, at 10:15 am. Include the name of anyone with whom you collaborated at the top of the assignment.</p>
<p>Submit your responses as either an HTML file or a PDF file on Canvas. Also, please upload it to your website.</p>
<p>Save the file (found on Canvas) crime_simple.txt to the same folder as this file (your Rmd file for Assignment 3).</p>
<p>Load the data.</p>
<pre class="r"><code>setwd(&quot;/Users/johannadoherty/Documents/FALL 21/CRIM 250/Assign 3&quot;)
library(readr)
library(knitr)
dat.crime &lt;- read_delim(&quot;crime_simple.txt&quot;, delim = &quot;\t&quot;)</code></pre>
<pre><code>## Rows: 47 Columns: 14</code></pre>
<pre><code>## ── Column specification ────────────────────────────────────────────────────────
## Delimiter: &quot;\t&quot;
## dbl (14): R, Age, S, Ed, Ex0, Ex1, LF, M, N, NW, U1, U2, W, X</code></pre>
<pre><code>## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
<p>This is a dataset from a textbook by Brian S. Everitt about crime in the US in 1960. The data originate from the Uniform Crime Report of the FBI and other government sources. The data for 47 states of the USA are given.</p>
<p>Here is the codebook:</p>
<p>R: Crime rate: # of offenses reported to police per million population</p>
<p>Age: The number of males of age 14-24 per 1000 population</p>
<p>S: Indicator variable for Southern states (0 = No, 1 = Yes)</p>
<p>Ed: Mean of years of schooling x 10 for persons of age 25 or older</p>
<p>Ex0: 1960 per capita expenditure on police by state and local government</p>
<p>Ex1: 1959 per capita expenditure on police by state and local government</p>
<p>LF: Labor force participation rate per 1000 civilian urban males age 14-24</p>
<p>M: The number of males per 1000 females</p>
<p>N: State population size in hundred thousands</p>
<p>NW: The number of non-whites per 1000 population</p>
<p>U1: Unemployment rate of urban males per 1000 of age 14-24</p>
<p>U2: Unemployment rate of urban males per 1000 of age 35-39</p>
<p>W: Median value of transferable goods and assets or family income in tens of $</p>
<p>X: The number of families per 1000 earning below 1/2 the median income</p>
<p>We are interested in checking whether the reported crime rate (# of offenses reported to police per million population) and the average education (mean number of years of schooling for persons of age 25 or older) are related.</p>
<ol style="list-style-type: decimal">
<li>How many observations are there in the dataset? To what does each observation correspond?</li>
</ol>
<pre class="r"><code>dim(dat.crime)</code></pre>
<pre><code>## [1] 47 14</code></pre>
<p><strong>There are 14 columns and 47 observations (or rows) in this data set. Each observation corresponds to a different state in the US.</strong></p>
<ol start="2" style="list-style-type: decimal">
<li>Draw a scatterplot of the two variables. Calculate the correlation between the two variables. Can you come up with an explanation for this relationship?</li>
</ol>
<pre class="r"><code>plot(dat.crime$Ed, dat.crime$R, main=&quot;Relationship between Education Level and Reported Crime&quot;,
    xlab=&quot;Education Level in Yearsx10&quot;, ylab=&quot;Reported Crime per Million Population&quot;)</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-23-1.png" width="576" /></p>
<pre class="r"><code>cor(dat.crime$Ed, dat.crime$R)</code></pre>
<pre><code>## [1] 0.3228349</code></pre>
<p><strong>There is not an extremely defined relationship here, but it is slightly positively correlated with a correlation of .3228 as calculated above. A possible explanation for this relationship is that areas with people that have had more education may be more economically affluent and may be more likely to report crime that occurs. Since crime is more common in areas with lower socioeconomic statuses, people in these areas may be less likely to report given the commonality of these occurrences. So even if there are lower actual rates of crime in areas with higher education, there may be more reported crime.</strong></p>
<ol start="3" style="list-style-type: decimal">
<li>Regress reported crime rate (y) on average education (x) and call this linear model <code>crime.lm</code> and write the summary of the regression by using this code, which makes it look a little nicer <code>{r, eval=FALSE} kable(summary(crime.lm)$coef, digits = 2)</code>.</li>
</ol>
<pre class="r"><code># Remember to remove eval=FALSE above!
crime.lm &lt;- lm(formula = R ~ Ed, data = dat.crime)
summary(crime.lm)</code></pre>
<pre><code>## 
## Call:
## lm(formula = R ~ Ed, data = dat.crime)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -60.061 -27.125  -4.654  17.133  91.646 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept) -27.3967    51.8104  -0.529   0.5996  
## Ed            1.1161     0.4878   2.288   0.0269 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 37.01 on 45 degrees of freedom
## Multiple R-squared:  0.1042, Adjusted R-squared:  0.08432 
## F-statistic: 5.236 on 1 and 45 DF,  p-value: 0.02688</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Are the four assumptions of linear regression satisfied? To answer this, draw the relevant plots. (Write a maximum of one sentence per assumption.)</li>
</ol>
<pre class="r"><code>plot(crime.lm, which=1)</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<p><strong>1)Linearity: as seen in the scatterplot from question 2, the relationship between the two variables does not look straight, and also looking at the Residuals vs. Fitted plot, the data points are not evenly spread along the regression line, so there seems to be an issue of non-constant variance and the linearity assumption is not met. .</strong></p>
<pre class="r"><code>plot(dat.crime$Ed, crime.lm$residuals, ylim=c(-15,15), main=&quot;Residuals vs. x&quot;, xlab=&quot;x, Education&quot;, ylab=&quot;Residuals&quot;)
abline(h = 0, lty=&quot;dashed&quot;)</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<p><strong>2) Independence: As seen in the above residuals vs. x plot, there are no patterns meaning that the data are likely independent of each other.</strong></p>
<pre class="r"><code>plot(dat.crime$R, dat.crime$Ed)</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<p><strong>3) Homoscedasticity: In the y,x scatterplot above, the relationship between the data does not look linear, indicating a difference in the variability in y values of x, so this assumption is not met.</strong></p>
<pre class="r"><code>plot(crime.lm, which=2)</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<p><strong>4)Normal Population: The Normal QQ plot does not look great both at the top and the bottom. It looks pretty normally distributed in the middle, but the top is pretty far off so we can not assume this condition is satisfied..</strong></p>
<ol start="5" style="list-style-type: decimal">
<li>Is the relationship between reported crime and average education statistically significant? Report the estimated coefficient of the slope, the standard error, and the p-value. What does it mean for the relationship to be statistically significant?</li>
</ol>
<p><strong>Given that the R-squared value of the linear regression is low (0.1042), the relationship between reported crime and average education is not statistically significant. The coefficient of the slope is 1.1161, and the p-value is 0.02668. If the relationship were statistically significant it would mean that changes in the dependent variable are correlated with changes in the independent variable.</strong></p>
<ol start="6" style="list-style-type: decimal">
<li>How are reported crime and average education related? In other words, for every unit increase in average education, how does reported crime rate change (per million) per state?</li>
</ol>
<p><strong>The slope in our model tells us that for every 1 year increase in the average length of education in a given state, the # of crimes reported to the police per million population for that state will increase by 1.1161. This is not a causal interpretation, but this is the predicted relationship between reported crime and average education.</strong></p>
<ol start="7" style="list-style-type: decimal">
<li>Can you conclude that if individuals were to receive more education, then crime will be reported more often? Why or why not?</li>
</ol>
<p><strong>There are two issues with making this conclusion based on this data. Firstly linear regression provides a prediction based on a correlation and should not be used to make causal statements. If anything, one could say that more education is related to more reporting of crime, but no causal statements should be made. Secondly, it is difficult to assume either of these statements are accurate when some of the assumptions were not met. If all four assumptions for linear regression had been satisfied then we would have more confidence in the predictions made using this regression. Since this is not the case, it is possible that a linear model is not the right fit for this relationship, making it hard to make even correlational judgments based on this regression. </strong></p>
<p>#title: “Exam 2” ##author: “Johanna Doherty” date: “11/01/2021” output: html_document</p>
<p><strong>Instructions</strong></p>
<ol style="list-style-type: lower-alpha">
<li><p>Create a folder in your computer (a good place would be under Crim 250, Exams).</p></li>
<li><p>Download the dataset from the Canvas website (sim.data.csv) onto that folder, and save your Exam 2.Rmd file in the same folder.</p></li>
<li><p>Data description: This dataset provides (simulated) data about 200 police departments in one year. It contains information about the funding received by the department as well as incidents of police brutality. Suppose this dataset (sim.data.csv) was collected by researchers to answer this question: <strong>“Does having more funding in a police department lead to fewer incidents of police brutality?”</strong></p></li>
<li><p>Codebook:</p></li>
</ol>
<ul>
<li>funds: How much funding the police department received in that year in millions of dollars.</li>
<li>po.brut: How many incidents of police brutality were reported by the department that year.</li>
<li>po.dept.code: Police department code</li>
</ul>
<p><strong>Problem 1: EDA (10 points)</strong></p>
<p>Describe the dataset and variables. Perform exploratory data analysis for the two variables of interest: funds and po.brut.</p>
<pre class="r"><code>setwd(&quot;/Users/johannadoherty/Documents/FALL 21/CRIM 250/EXAM 2&quot;)
dat &lt;- read.csv(file = &#39;sim.data.csv&#39;)
names(dat)</code></pre>
<pre><code>## [1] &quot;po.dept.code&quot; &quot;funds&quot;        &quot;po.brut&quot;</code></pre>
<pre class="r"><code>dim(dat)</code></pre>
<pre><code>## [1] 200   3</code></pre>
<pre class="r"><code>summary(dat)</code></pre>
<pre><code>##   po.dept.code        funds          po.brut     
##  Min.   :  1.00   Min.   :21.40   Min.   : 0.00  
##  1st Qu.: 50.75   1st Qu.:51.67   1st Qu.:14.00  
##  Median :100.50   Median :59.75   Median :19.00  
##  Mean   :100.50   Mean   :61.04   Mean   :18.14  
##  3rd Qu.:150.25   3rd Qu.:72.17   3rd Qu.:22.00  
##  Max.   :200.00   Max.   :99.70   Max.   :29.00</code></pre>
<pre class="r"><code>plot(dat$funds, dat$po.brut, main=&quot;Scatterplot Comparing Funds and Police Brutality&quot;, xlab=&quot;Funds, in millions&quot;, ylab=&quot;Police Brutality Incidents&quot;)</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<p><strong>This data set has 3 columns with 200 rows, which represents 200 police departments’ data for the three variables: police department code, police brutality incidents, and funding available to the department. As we can see in the scatterplot above showing the relationship between the amount of funding and the quantity of police brutality incidents, there is a pretty clear negative correlation. From looking at this scatterplot it seems as though increased funding is correlated with fewer police brutality incidents. .</strong></p>
<p><strong>Problem 2: Linear regression (30 points)</strong></p>
<ol style="list-style-type: lower-alpha">
<li>Perform a simple linear regression to answer the question of interest. To do this, name your linear model “reg.output” and write the summary of the regression by using “summary(reg.output)”.</li>
</ol>
<pre class="r"><code># Remember to remove eval=FALSE!!
reg.output &lt;- lm(formula = dat$po.brut ~ dat$funds, data = dat)
summary(reg.output)</code></pre>
<pre><code>## 
## Call:
## lm(formula = dat$po.brut ~ dat$funds, data = dat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.9433 -0.2233  0.2544  0.5952  1.1803 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 40.543069   0.282503  143.51   &lt;2e-16 ***
## dat$funds   -0.367099   0.004496  -81.64   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9464 on 198 degrees of freedom
## Multiple R-squared:  0.9712, Adjusted R-squared:  0.971 
## F-statistic:  6666 on 1 and 198 DF,  p-value: &lt; 2.2e-16</code></pre>
<ol start="2" style="list-style-type: lower-alpha">
<li>Report the estimated coefficient, standard error, and p-value of the slope. Is the relationship between funds and incidents statistically significant? Explain.</li>
</ol>
<p><strong>The estimated coefficient is -0.367099, the standard error is 0.004496, and the p-value of the slope is 2.2e-16. Given that the p-value is extremely small, and assuming we are using 0.05 as our significance value, then the relationship between funds and brutality incidents is statistically significant. This p-value essentially tells us that if the null hypothesis (no relationship between the two variables) were true, the chances of observing a statistic like one would be 2.2e-16, which is a very small chance. Given the summary of this linear regression, it seems that there is a pretty strong negative association between the two variables. Looking at this data and the regression we can say that a one million dollar increase in funding for a department is associated with .367099 fewer incidents of police brutality for a given year.</strong></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Draw a scatterplot of po.brut (y-axis) and funds (x-axis). Right below your plot command, use abline to draw the fitted regression line, like this:</li>
</ol>
<pre class="r"><code># Remember to remove eval=FALSE!!
plot(dat$funds, dat$po.brut, main = &quot;Regression of Funds over Brutality&quot;, xlab=&quot;Funds in millions&quot;, ylab=&quot;Brutality Incidents&quot;)
abline(reg.output, col = &quot;red&quot;, lwd=2)</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-31-1.png" width="672" /> Does the line look like a good fit? Why or why not?</p>
<p><strong>The line looks like an ok fit, but the points definitely stray from the line at the top and bottom of the regression line. While it is certainly not a perfect linear fit, it seems close enough to continue with the analysis and check the other assumptions. </strong></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Are the four assumptions of linear regression satisfied? To answer this, draw the relevant plots. (Write a maximum of one sentence per assumption.) If not, what might you try to do to improve this (if you had more time)?</li>
</ol>
<pre class="r"><code>plot(dat$funds, dat$po.brut, main=&quot;Scatterplot Comparing Funds and Police Brutality&quot;, xlab=&quot;Funds, in millions&quot;, ylab=&quot;Police Brutality Incidents&quot;)</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
<p><strong>1. Linearity: Using a scatterplot of x,y or funds,po.brut we can see that the relationship between the two variables looks vaguely linear. It is not perfectly linear but it is close enough to say that the assumption has been satisfied for the purposes of this analysis. </strong></p>
<pre class="r"><code>plot(dat$funds, reg.output$residuals, main = &quot;Residuals vs. X Plot&quot;, xlab=&quot;X, Funds&quot;, ylab=&quot;Residuals&quot;)
abline(h = 0, lty=&quot;dashed&quot;)</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
<p><strong>2. Independence: Looking at the residuals vs. X plot above, there is a definite pattern to the data, meaning that the data are likely not independent of each other and this assumption is not satisfied.</strong></p>
<pre class="r"><code>plot(dat$po.brut, dat$funds, main=&quot;Y vs. X Scatterplot&quot;)</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-34-1.png" width="672" /></p>
<p><strong>3.Homoscedasticity: Looking at the y vs. x scatterplot above, there is no fan shape or tendency for the data to grow or shrink in any given area observed. This means that this assumption has been met and that the variability in y about the same for all values of x. </strong></p>
<pre class="r"><code>plot(reg.output, which=2)</code></pre>
<p><img src="Assignments_files/figure-html/unnamed-chunk-35-1.png" width="672" /></p>
<p><strong>4. Normality: In the Normal QQ plot seen above, we can see that the points stray pretty far from the line at the top and bottom of the line. While the section of the data that follows the line has many more points, there are still a lot of points at the tails that do not follow the line and stray pretty far. Based on this, the normality assumption is not met for this data. </strong></p>
<p><strong>In order to fix this lack of model fit, I would use data transformation, like taking the log of y or squaring y, to see if these changes make the data fit the model a little better. If the transformed data fits the model more accurately, we can then proceed with analysis and later un-transform the results to make accurate statements.</strong></p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Answer the question of interest based on your analysis.</li>
</ol>
<p><strong>Based on the linear regression analysis above, there are a few factors to consider in terms of answering the question of interest. Based on the summary of the regression, there is a strong negative correlation with an R-squared of .9712, and the relationship is statistically significant given that the p-value is 2.2e-16, which is much smaller than our significance value of 0.05. Using the regression model, we would say that a one million dollar increase in funding for a department is associated with .367099 fewer incidents of police brutality for a given year. However, given that two of the assumptions have not been met, and that the two that have been met are not very solidly met, it’s not clear that we are really able to use this regression model with confidence. It’s possible that while there is a clear relationship between these variables, it may not be a linear relationship, which means that this regression model might not be the best fit for this data.</strong></p>
<p><strong>Problem 3: Data ethics (10 points)</strong></p>
<p>Describe the dataset. Considering our lecture on data ethics, what concerns do you have about the dataset? Once you perform your analysis to answer the question of interest using this dataset, what concerns might you have about the results?</p>
<p><strong>This data set is based on simulated data from 200 police departments. My concern with this data set lies in what information the algorithm/simulation was based on and how representative it truly is of real data from real departments. I would like more information on how the simulated data was created/collected and what testing it went through to make sure that it is truly representative of the results from a range of diverse real departments. I’m also curious about the size of departments used, if we are comparing the Philadelphia PD to a tiny department in the middle of PA, then using the raw number of incidents would not be a good comparison given the difference in sizes. There would need to be a lot more clarity about the source of the data in order to use this analysis with more confidence.</strong></p>
<p><strong>Given these concerns about the source of the data, after running my analysis my next concern would be that these results/relationship would be used to make assumptions about all police forces, regardless of whether the data is truly representative or not. Additionally, there are probably some confounding variables in this relationship, and it would be important to look at what is really causing this relationship before definitively deciding that increasing funding will reduce police brutality. We would also have to consider the effect that increasing funding to the police might have in other areas besides brutality. It seems to me that if the funding is not being spent in the right places, it’s possible it wouldn’t have the same effect as this data shows and could possibly even have a negative effect. Overall, given that the data is simulated, if is based on flawed or non-representative data, then any assumptions we make based on the data will not be accurate and should not be used to inform policy.</strong></p>
<table>
<tbody>
<tr class="odd">
<td align="right">title: “Assignment 4”</td>
</tr>
<tr class="even">
<td align="right">output: html_document</td>
</tr>
</tbody>
</table>
<p><strong>Chapter 3: Data Visualizations:</strong></p>
<pre class="r"><code>#eval=FALSE
library(tidyverse)</code></pre>
<pre><code>## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──</code></pre>
<pre><code>## ✓ tibble  3.1.4     ✓ dplyr   1.0.7
## ✓ tidyr   1.1.4     ✓ stringr 1.4.0
## ✓ purrr   0.3.4     ✓ forcats 0.5.1</code></pre>
<pre><code>## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()
## x purrr::map()    masks maps::map()</code></pre>
<pre class="r"><code>#&gt; ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──
#&gt; ✔ ggplot2 3.3.2     ✔ purrr   0.3.4
#&gt; ✔ tibble  3.0.3     ✔ dplyr   1.0.2
#&gt; ✔ tidyr   1.1.2     ✔ stringr 1.4.0
#&gt; ✔ readr   1.4.0     ✔ forcats 0.5.0
#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
#&gt; ✖ dplyr::filter() masks stats::filter()
#&gt; ✖ dplyr::lag()    masks stats::lag()</code></pre>
<p><strong>The above code is loading the tidyverse library which will allow us to have access to data sets, help, and functions that might be needed when using ggplot. The first line loads the tidyverse, and the rest of the information tells us which parts of base R conflict with the tidyverse library.</strong></p>
<pre class="r"><code>mpg
#&gt; # A tibble: 234 x 11
#&gt;   manufacturer model displ  year   cyl trans      drv     cty   hwy fl    class 
#&gt;   &lt;chr&gt;        &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;      &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; 
#&gt; 1 audi         a4      1.8  1999     4 auto(l5)   f        18    29 p     compa…
#&gt; 2 audi         a4      1.8  1999     4 manual(m5) f        21    29 p     compa…
#&gt; 3 audi         a4      2    2008     4 manual(m6) f        20    31 p     compa…
#&gt; 4 audi         a4      2    2008     4 auto(av)   f        21    30 p     compa…
#&gt; 5 audi         a4      2.8  1999     6 auto(l5)   f        16    26 p     compa…
#&gt; 6 audi         a4      2.8  1999     6 manual(m5) f        18    26 p     compa…
#&gt; # … with 228 more rows</code></pre>
<p><strong>This mpg data frame contains observations collected by the US Environmental Protection Agency on 38 models of car, and contains variables such as a car’s engine size and a car’s fuel efficiency on the highway. We can use this data frame in our analysis using ggplot tools. </strong></p>
<pre class="r"><code>ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy))</code></pre>
<p><strong>This code tells R to make a ggplot using the mpg data frame, and places displ on the x axis and hwy on the y axis. </strong></p>
<pre class="r"><code>ggplot(data = DATA) + GEOM_FUNCTION(mapping = aes(MAPPINGS))</code></pre>
<p><strong>This code creates a template to make plots in gg plot so that we can just replace the bracketed sections with what we want to plot instead of writing the code out entirely each time.</strong></p>
<pre class="r"><code># eval = FALSE
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, color = class))</code></pre>
<p><strong>This line of code maps aesthetics onto the variables in the plot. This particular line is mapping colors of data points to the class variable so that the class of each car can be easily seen in the scatterplot.</strong></p>
<pre class="r"><code>ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, size = class))

#&gt; Warning: Using size for a discrete variable is not advised.</code></pre>
<p><strong>This line of code continues with mapping aesthetics but instead of color it is mapping size onto the class variable. in this case, the class of each car can be seen by the size of the point it represents on the scatterplot.</strong></p>
<pre class="r"><code># Left
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, alpha = class))


# Right
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, shape = class))</code></pre>
<p><strong>These two chunks of code map transparency and shape onto the class variable, respectively. The class of each car is shown by the transparency on the first plot and by the shape on the second plot.</strong></p>
<pre class="r"><code>ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy), color = &quot;blue&quot;)</code></pre>
<p><strong>This code changes the color of all the points on the plot to blue, without having the color attached to any meaning or variable.</strong></p>
<pre class="r"><code>ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) + 
  facet_wrap(~ class, nrow = 2)</code></pre>
<p><strong>This code allows you to split the data into separate subplots, or facets. The variable that is being split into facets in this code is class.</strong></p>
<pre class="r"><code>ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) + 
  facet_grid(drv ~ cyl)</code></pre>
<p><strong>This code allows you to facet the plot based on the combination of two variables. We can use facet_grid, and then input the two variables in the parentheses.</strong></p>
<pre class="r"><code># left
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy))


# right
ggplot(data = mpg) + 
  geom_smooth(mapping = aes(x = displ, y = hwy))</code></pre>
<p><strong>These two lines of code make plots using two different geoms for the same data. The top chunk uses points and the bottom chunk uses a smooth geom to represent the data.</strong></p>
<pre class="r"><code>ggplot(data = mpg) + 
  geom_smooth(mapping = aes(x = displ, y = hwy, linetype = drv))</code></pre>
<p><strong>This code uses the geom smooth to separate the data into 3 different lines based on their value for variable drv. This allows us to see how data points with each response for drv look when mapped separately.</strong></p>
<pre class="r"><code>ggplot(data = mpg) +
  geom_smooth(mapping = aes(x = displ, y = hwy))

ggplot(data = mpg) +
  geom_smooth(mapping = aes(x = displ, y = hwy, group = drv))


ggplot(data = mpg) +
  geom_smooth(mapping = aes(x = displ, y = hwy, color = drv),show.legend = FALSE)</code></pre>
<p><strong>This code lets us set the group aesthetic to a categorical variable to draw multiple objects, and ggplot2 will draw a separate object for each unique value of the grouping variable.</strong></p>
<pre class="r"><code>ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) +
  geom_smooth(mapping = aes(x = displ, y = hwy))</code></pre>
<p><strong>This code allows us to display multiple geoms in the same plot, by adding multiple geom functions to ggplot.</strong></p>
<pre class="r"><code>ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + 
  geom_point() + 
  geom_smooth()</code></pre>
<p><strong>This code avoids repetition by passing a set of mappings to ggplot. ggplot2 will apply these mappings to each geom in the graph. This code will produce the same plot as the previous code, while avoiding any potential repetitions.</strong></p>
<pre class="r"><code>ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + 
  geom_point(mapping = aes(color = class)) + 
  geom_smooth()</code></pre>
<p><strong>This code allows us to place mappings in a geom function, which ggplot2 will then treat as local mappings for the intended layer. ggplot2 will then use these local mappings to overwrite the global mappings for that layer only. Because of this we can display different aesthetics in different layers.</strong></p>
<pre class="r"><code>ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + 
  geom_point(mapping = aes(color = class)) + 
  geom_smooth(data = filter(mpg, class == &quot;subcompact&quot;), se = FALSE)</code></pre>
<p><strong>This code allows us to do something similar to above, but instead of changing aesthetics for each layer we can change the specified data for each layer.</strong></p>
<pre class="r"><code>ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut))</code></pre>
<p><strong>This code creates a bar chart for the diamonds data set using cut and count. Even though count is not a variable in diamonds, ggplot can bin your data and then plot bin counts, the number of points that fall in each bin.</strong></p>
<pre class="r"><code>ggplot(data = diamonds) + 
  stat_count(mapping = aes(x = cut))</code></pre>
<p><strong>This code will give us the same plot as above, but using stat_count instead of geom_bar to create the count data points.</strong></p>
<pre class="r"><code>demo &lt;- tribble(
  ~cut,         ~freq,
  &quot;Fair&quot;,       1610,
  &quot;Good&quot;,       4906,
  &quot;Very Good&quot;,  12082,
  &quot;Premium&quot;,    13791,
  &quot;Ideal&quot;,      21551
)

ggplot(data = demo) +
  geom_bar(mapping = aes(x = cut, y = freq), stat = &quot;identity&quot;)</code></pre>
<p><strong>In the code above, we can change the stat of geom_bar from count to identity. This lets us map the height of the bars to the raw values of a y variable.</strong></p>
<pre class="r"><code>ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, y = stat(prop), group = 1))</code></pre>
<p><strong>We can also override the default mapping from transformed variables to aesthetics. In this code we can create a bar chart of proportion instead of count.</strong></p>
<pre class="r"><code>ggplot(data = diamonds) + 
  stat_summary(mapping = aes(x = cut, y = depth),
    fun.min = min,
    fun.max = max,
    fun = median)</code></pre>
<p><strong>This code uses stat_summary to draw more attention to the transformations in the data. It summarizes the y values for each x value, to draw attention to the summary that we are computing.</strong></p>
<pre class="r"><code>ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, colour = cut))
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = cut))</code></pre>
<p><strong>Both the color aesthetic and fill allow us to color the bar chart for a more visual display of the data.</strong></p>
<pre class="r"><code>ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity))</code></pre>
<p><strong>This code maps fill onto another variable, which creates an automatically color-coded stacked bar chart with the data.</strong></p>
<pre class="r"><code>ggplot(data = diamonds, mapping = aes(x = cut, fill = clarity)) + 
  geom_bar(alpha = 1/5, position = &quot;identity&quot;)
ggplot(data = diamonds, mapping = aes(x = cut, colour = clarity)) + 
  geom_bar(fill = NA, position = &quot;identity&quot;)</code></pre>
<p><strong>This code is used to place each object exactly where it falls in the context of the graph. When used on bar graphs, it can overlap the bars, so to see the overlapping we can make the bars slightly transparent by setting alpha to a small value, or completely transparent by setting fill = NA.</strong></p>
<pre class="r"><code>ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity), position = &quot;fill&quot;)</code></pre>
<p><strong>This code makes each set of stacked bars the same height, so that we can more easily compare proportions across groups.</strong></p>
<pre class="r"><code>ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity), position = &quot;dodge&quot;)</code></pre>
<p><strong>This code places overlapping objects right next to one another so that we can more easily compare individual values.</strong></p>
<pre class="r"><code>ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy), position = &quot;jitter&quot;)</code></pre>
<p><strong>We can avoid the isseu of gridding and overplotting by setting the position adjustment to “jitter” which will add a small amount of random noise to each point. This code will spread the points out more because no two points are likely to receive the same amount of random noise, and make it easier to see what is really going on with the data.</strong></p>
<pre class="r"><code>ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + 
  geom_boxplot()
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + 
  geom_boxplot() +
  coord_flip()</code></pre>
<p><strong>This code switches the x and y axes on the graph, which can be used to make horizontal boxplots or to avoid too long labels.</strong></p>
<pre class="r"><code>nz &lt;- map_data(&quot;nz&quot;)

ggplot(nz, aes(long, lat, group = group)) +
  geom_polygon(fill = &quot;white&quot;, colour = &quot;black&quot;)

ggplot(nz, aes(long, lat, group = group)) +
  geom_polygon(fill = &quot;white&quot;, colour = &quot;black&quot;) +
  coord_quickmap()</code></pre>
<p><strong>This code sets the aspect ratio correctly for maps, which is important to use when plotting spatial data with ggplot2</strong></p>
<pre class="r"><code>bar &lt;- ggplot(data = diamonds) + 
  geom_bar(
    mapping = aes(x = cut, fill = cut), 
    show.legend = FALSE,
    width = 1
  ) + 
  theme(aspect.ratio = 1) +
  labs(x = NULL, y = NULL)

bar + coord_flip()
bar + coord_polar()</code></pre>
<p><strong>This code uses polar coordinates, which can reveal interesting connections between a bar chart and a Coxcomb chart.</strong></p>
<pre class="r"><code>ggplot(data = DATA) + GEOM_FUNCTION&gt;(mapping = aes(MAPPINGS) stat = STAT&gt; position = POSITION) + COORDINATE_FUNCTION +  FACET_FUNCTION</code></pre>
<p><strong>The above code is our new template, with added position adjustments, stats, coordinate systems, and faceting.</strong></p>
<p><strong>Chapter 28: Graphics for Communication</strong></p>
<pre class="r"><code>library(tidyverse)</code></pre>
<p><strong>The above code is once again loading the tidyverse library which will allow us to have access to data sets, help, and functions that might be needed when using ggplot</strong></p>
<pre class="r"><code>ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(color = class)) +
  geom_smooth(se = FALSE) +
  labs(title = &quot;Fuel efficiency generally decreases with engine size&quot;)</code></pre>
<p><strong>The above code adds labels to the graph with the labs() function, this example adds a plot title. This is useful when turning an exploratory graphic into an expository graphic.</strong></p>
<pre class="r"><code>ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(color = class)) +
  geom_smooth(se = FALSE) +
  labs( title = &quot;Fuel efficiency generally decreases with engine size&quot;,
    subtitle = &quot;Two seaters (sports cars) are an exception because of their light weight&quot;,
    caption = &quot;Data from fueleconomy.gov&quot; )</code></pre>
<p><strong>This code adds subtitles, which adds additional detail in a smaller font beneath the title, and a caption, which adds text at the bottom right of the plot, often used to describe the source of the data.</strong></p>
<pre class="r"><code>ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = class)) +
  geom_smooth(se = FALSE) +
  labs(
    x = &quot;Engine displacement (L)&quot;,
    y = &quot;Highway fuel economy (mpg)&quot;,
    colour = &quot;Car type&quot;
  )</code></pre>
<p><strong>This code replaces the axis and legend titles with a more in-depth description including unit for more clarity.</strong></p>
<pre class="r"><code>df &lt;- tibble(
  x = runif(10),
  y = runif(10)
)
ggplot(df, aes(x, y)) +
  geom_point() +
  labs(
    x = quote(sum(x[i] ^ 2, i == 1, n)),
    y = quote(alpha + beta + frac(delta, theta))
  )</code></pre>
<p><strong>This code allows us to use mathematical equations rather than text strings as labels for the graphs.</strong></p>
<pre class="r"><code>best_in_class &lt;- mpg %&gt;%
  group_by(class) %&gt;%
  filter(row_number(desc(hwy)) == 1)

ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = class)) +
  geom_text(aes(label = model), data = best_in_class)</code></pre>
<p><strong>We can use this code to label individual observations or groups of observations, to make it easier to point out the interesting parts of a graph. It’s good to use geom_text() because it has an additional aesthetic: label, which lets us add textual labels to plots.</strong></p>
<pre class="r"><code>ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = class))

ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = class)) +
  scale_x_continuous() +
  scale_y_continuous() +
  scale_colour_discrete()</code></pre>
<p><strong>These two chunks show that when you type the first chunk of code, ggplot will automatically add default scales behind the scenes, which are shown in the second chunk of code.</strong></p>
<pre class="r"><code>ggplot(mpg, aes(displ, hwy)) +
  geom_point() +
  scale_y_continuous(breaks = seq(15, 40, by = 5))</code></pre>
<p><strong>This code uses breaks by overriding the default choice.Breaks controls the position of the ticks, or the values associated with the keys.</strong></p>
<pre class="r"><code>ggplot(mpg, aes(displ, hwy)) +
  geom_point() +
  scale_x_continuous(labels = NULL) +
  scale_y_continuous(labels = NULL)</code></pre>
<p><strong>This code uses labels, but sets them to null to suppress the labels altogether, which is useful for maps, or for publishing plots where you can’t share the absolute numbers.</strong></p>
<pre class="r"><code>presidential %&gt;%
  mutate(id = 33 + row_number()) %&gt;%
  ggplot(aes(start, id)) +
    geom_point() +
    geom_segment(aes(xend = end, yend = id)) +
    scale_x_date(NULL, breaks = presidential$start, date_labels = &quot;&#39;%y&quot;)</code></pre>
<p><strong>This code is useful for when you have relatively few data points and allows us to highlight exactly where the observations occur.</strong></p>
<pre class="r"><code>base &lt;- ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = class))

base + theme(legend.position = &quot;left&quot;)
base + theme(legend.position = &quot;top&quot;)
base + theme(legend.position = &quot;bottom&quot;)
base + theme(legend.position = &quot;right&quot;) # the default</code></pre>
<p><strong>we can use theme settings to control the overall position of the legend. The theme setting legend.position controls where the legend is drawn.</strong></p>
<pre class="r"><code>ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = class)) +
  geom_smooth(se = FALSE) +
  theme(legend.position = &quot;bottom&quot;) +
  guides(colour = guide_legend(nrow = 1, override.aes = list(size = 4)))
#&gt; `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><strong>This code controls the number of rows the legend uses with nrow, and overrides one of the aesthetics to make the points bigger.</strong></p>
<pre class="r"><code>ggplot(diamonds, aes(carat, price)) +
  geom_bin2d()

ggplot(diamonds, aes(log10(carat), log10(price))) +
  geom_bin2d()</code></pre>
<p><strong>This code log transforms the data so that we can see the precise relationships more clearly.</strong></p>
<pre class="r"><code>ggplot(diamonds, aes(carat, price)) +
  geom_bin2d() + 
  scale_x_log10() + 
  scale_y_log10()</code></pre>
<p><strong>After the transformation, the axes are now labelled with transformed values, so we can instead do it with the scale. This is visually identical, except the axes are labelled on the original data scale.</strong></p>
<pre class="r"><code>df &lt;- tibble(
  x = rnorm(10000),
  y = rnorm(10000)
)
ggplot(df, aes(x, y)) +
  geom_hex() +
  coord_fixed()

ggplot(df, aes(x, y)) +
  geom_hex() +
  viridis::scale_fill_viridis() +
  coord_fixed()</code></pre>
<p><strong>This code lets us use scale_colour_viridis which is provided by the viridis package. It’s a continuous analog of the categorical ColorBrewer scales. it is a continuous colour scheme that has good perceptual properties.</strong></p>
<pre class="r"><code>ggplot(mpg, mapping = aes(displ, hwy)) +
  geom_point(aes(color = class)) +
  geom_smooth() +
  coord_cartesian(xlim = c(5, 7), ylim = c(10, 30))

mpg %&gt;%
  filter(displ &gt;= 5, displ &lt;= 7, hwy &gt;= 10, hwy &lt;= 30) %&gt;%
  ggplot(aes(displ, hwy)) +
  geom_point(aes(color = class)) +
  geom_smooth()</code></pre>
<p><strong>This code is an example of how to control the plot limits by either Adjusting what data are plotted, Setting the limits in each scale, or Setting xlim and ylim in coord_cartesian.</strong></p>
<pre class="r"><code>suv &lt;- mpg %&gt;% filter(class == &quot;suv&quot;)
compact &lt;- mpg %&gt;% filter(class == &quot;compact&quot;)
eval=FALSE

ggplot(suv, aes(displ, hwy, colour = drv)) +
  geom_point()
eval=FALSE

ggplot(compact, aes(displ, hwy, colour = drv)) +
  geom_point()</code></pre>
<p><strong>We can also set the limits on individual scales. When we reduce the limits, it is basically equivalent to subsetting the data. It is generally more useful if you want expand the limits, for example, to match scales across different plots.</strong></p>
<pre class="r"><code>x_scale &lt;- scale_x_continuous(limits = range(mpg$displ))
y_scale &lt;- scale_y_continuous(limits = range(mpg$hwy))
col_scale &lt;- scale_colour_discrete(limits = unique(mpg$drv))


ggplot(suv, aes(displ, hwy, colour = drv)) +
  geom_point() +
  x_scale +
  y_scale +
  col_scale


ggplot(compact, aes(displ, hwy, colour = drv)) +
  geom_point() +
  x_scale +
  y_scale +
  col_scale</code></pre>
<p><strong>This code attempts to overcome the plot limits problem by sharing scales across multiple plots, training the scales with the limits of the full data.</strong></p>
<pre class="r"><code>ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(color = class)) +
  geom_smooth(se = FALSE) +
  theme_bw()</code></pre>
<p><strong>we can customise the non-data elements of your plot with a theme as seen in the above code.</strong></p>
<pre class="r"><code>ggsave(&quot;my-plot.pdf&quot;)
#&gt; Saving 7 x 4.33 in image</code></pre>
<p><strong>ggsave helps to get the plots out of R and into the final write up by saving them to the disk.</strong></p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
